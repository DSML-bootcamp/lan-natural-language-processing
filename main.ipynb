{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab. Natural Lenguage Processing\n",
    "### SMS: SPAM or HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read Data for the Fraudulent Email Kaggle Challenge\n",
    "- Reduce the training set to speead up development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "## Read Data for the Fraudulent Email Kaggle Challenge\n",
    "train = pd.read_csv(\"data/kg_train.csv\",encoding='latin-1')\n",
    "test = pd.read_csv(\"data/kg_test.csv\",encoding='latin-1')\n",
    "# Reduce the training set to speead up development. \n",
    "# Modify for final system\n",
    "train = train.head(1000)\n",
    "test = test.head(1000)\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "train.fillna(\"\",inplace=True)\n",
    "test.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nora--Cheryl has emailed dozens of memos about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Sir=2FMadam=2C I know that this proposal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1\n",
       "1                                           Will do.      0\n",
       "2  Nora--Cheryl has emailed dozens of memos about...      0\n",
       "3  Dear Sir=2FMadam=2C I know that this proposal ...      1\n",
       "4                                                fyi      0"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usiness is for the fact that the deceased man ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They are happy to adjust to the afternoon. I a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lael Brainard was confirmed 78-19 this afterno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H &lt;hrod17@clintonemail.com&gt;Friday March 26 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n;\"&gt; Dear Good Friend,&lt;br&gt;&lt;br&gt;&lt;br&gt;I am happy t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  usiness is for the fact that the deceased man ...\n",
       "1  They are happy to adjust to the afternoon. I a...\n",
       "2  Lael Brainard was confirmed 78-19 this afterno...\n",
       "3  H <hrod17@clintonemail.com>Friday March 26 201...\n",
       "4  n;\"> Dear Good Friend,<br><br><br>I am happy t..."
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's divide the training and test set into two partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already have training and testing into two partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...\n",
       "1                                               Will do.\n",
       "2      Nora--Cheryl has emailed dozens of memos about...\n",
       "3      Dear Sir=2FMadam=2C I know that this proposal ...\n",
       "4                                                    fyi\n",
       "                             ...                        \n",
       "995    So what's the latest? It sounds contradictory ...\n",
       "996    TRANSFER OF 36,759,000.00 MILLION POUNDS TO YO...\n",
       "997    Barb I will call to explain. Are you back in t...\n",
       "998      Yang on travelNot free tonite.May work tomorrow\n",
       "999    sbwhoeopSunday February 21 2010 7:42 PMHShaunH...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      usiness is for the fact that the deceased man ...\n",
       "1      They are happy to adjust to the afternoon. I a...\n",
       "2      Lael Brainard was confirmed 78-19 this afterno...\n",
       "3      H <hrod17@clintonemail.com>Friday March 26 201...\n",
       "4      n;\"> Dear Good Friend,<br><br><br>I am happy t...\n",
       "                             ...                        \n",
       "995    Dear Friend,Do accept my sincere apologies if ...\n",
       "996    FROM THE DESK OF:MR.WANG QINHANG SENG BANK LTD...\n",
       "997    He can speak at 7pm. He said that it does not ...\n",
       "998    Mary Landrieu asked me to attend a dinner abou...\n",
       "999    Oscar should have printed gates shangrila conf...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "print(string.punctuation)\n",
    "print(stopwords.words(\"english\")[100:110])\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we have to clean the html code removing words\n",
    "\n",
    "- First we remove inline JavaScript/CSS\n",
    "- Then we remove html comments. This has to be done before removing regular tags since comments can contain '>' characters\n",
    "- Next we can remove the remaining tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(html):\n",
    "    \"\"\"Copied from NLTK package.\n",
    "    Remove HTML markup from the given string.\n",
    "\n",
    "    :param html: the HTML string to be cleaned\n",
    "    :type html: str\n",
    "    :rtype: str\"\"\"\n",
    "    # First we remove inline JavaScript/CSS:\n",
    "    cleaned = html.strip()\n",
    "    cleaned = re.sub(r\"(?is)<(script|style).*?>.*?(</\\1>)\", \" \", cleaned)\n",
    "    \n",
    "    # Then we remove html comments. This has to be done before removing regular\n",
    "    # tags since comments can contain '>' characters.\n",
    "    cleaned = re.sub(r\"(?s)<!--(.*?)-->[\\n]?\", \" \", cleaned)\n",
    "    \n",
    "    # Next we can remove the remaining tags:\n",
    "    cleaned = re.sub(r\"(?s)<.*?>\", \" \", cleaned)   \n",
    "    \n",
    "\n",
    "    return cleaned.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply clean_html function to each value in the training series\n",
    "train['text'] = train['text'].map(clean_html)\n",
    "test['text'] = test['text'].map(clean_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all the special characters\n",
    "    \n",
    "- Remove numbers\n",
    "    \n",
    "- Remove all single characters\n",
    " \n",
    "- Remove single characters from the start\n",
    "\n",
    "- Substitute multiple spaces with single space\n",
    "\n",
    "- Remove prefixed 'b'\n",
    "\n",
    "- Convert to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a function that does all the above :\n",
    "def preprocess(pdseries):\n",
    "    # Define the punctuation characters to remove\n",
    "    punctuation = string.punctuation\n",
    "    \n",
    "    def process_text(text):\n",
    "        if not isinstance(text, str):\n",
    "            return text\n",
    "        \n",
    "        # Remove special characters and digits\n",
    "        text = ''.join(char for char in text if char not in punctuation and not char.isdigit())\n",
    "        \n",
    "        # Remove all single characters and single characters from the start\n",
    "        text = ' '.join(word for word in text.split() if len(word) > 1)\n",
    "        \n",
    "        # Substitute multiple spaces with a single space and remove prefixed 'b'\n",
    "        text = ' '.join(text.split()).lstrip('b')\n",
    "        \n",
    "        # Convert to lowercase and remove Unicode characters\n",
    "        text = text.lower()\n",
    "        text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    # Apply the process_text function to each element in the series\n",
    "    return pdseries.map(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = preprocess(train['text'])\n",
    "test['text'] = preprocess(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      dear sir strictly private business proposal am...\n",
       "1                                                will do\n",
       "2      noracheryl has emailed dozens of memos about h...\n",
       "3      dear sirfmadamc know that this proposal might ...\n",
       "4                                                    fyi\n",
       "                             ...                        \n",
       "995    so whats the latest it sounds contradictory an...\n",
       "996    transfer of million pounds to youraccountmy na...\n",
       "997    barb will call to explain are you back in the ...\n",
       "998       yang on travelnot free tonitemay work tomorrow\n",
       "999    sbwhoeopsunday february pmhshaunh just talked ...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      usiness is for the fact that the deceased man ...\n",
       "1      they are happy to adjust to the afternoon am g...\n",
       "2      lael brainard was confirmed this afternoonmigu...\n",
       "3      friday march amsbwhoeopãâãâãâ rei have extende...\n",
       "4      dear good friend am happy to inform you about ...\n",
       "                             ...                        \n",
       "995    dear frienddo accept my sincere apologies if m...\n",
       "996    from the desk ofmrwang qinhang seng bank ltdde...\n",
       "997    he can speak at pm he said that it does not ha...\n",
       "998    mary landrieu asked me to attend dinner about ...\n",
       "999    oscar should have printed gates shangrila conf...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Now let's work on removing stopwords\n",
    "Remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print (stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_to_remove = stopwords.words(\"english\")\n",
    "\n",
    "# Remove stopwords\n",
    "train['text'] = train['text'].map(lambda x: ' '.join(word for word in x.split() if word.lower() not in stopwords_to_remove) if isinstance(x, str) else x)\n",
    "test['text'] = test['text'].map(lambda x: ' '.join(word for word in x.split() if word.lower() not in stopwords_to_remove) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tame Your Text with Lemmatization\n",
    "Break sentences into words, then use lemmatization to reduce them to their base form (e.g., \"running\" becomes \"run\"). See how this creates cleaner data for analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Break sentences into words and lemmatize\n",
    "train['text'] = train['text'].map(lambda x: ' '.join(lemmatizer.lemmatize(word) for word in x.split()) if isinstance(x, str) else x)\n",
    "test['text'] = test['text'].map(lambda x: ' '.join(lemmatizer.lemmatize(word) for word in x.split()) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      dear sir strictly private business proposal mi...\n",
       "1                                                       \n",
       "2      noracheryl emailed dozen memo haiti weekend pl...\n",
       "3      dear sirfmadamc know proposal might surprise e...\n",
       "4                                                    fyi\n",
       "                             ...                        \n",
       "995    whats latest sound contradictory af decide sha...\n",
       "996    transfer million pound youraccountmy name mrej...\n",
       "997                       barb call explain back country\n",
       "998          yang travelnot free tonitemay work tomorrow\n",
       "999    sbwhoeopsunday february pmhshaunh talked shaun...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      usiness fact deceased man foreigner authorized...\n",
       "1      happy adjust afternoon going suggest pm start ...\n",
       "2      lael brainard confirmed afternoonmiguel rodrig...\n",
       "3      friday march amsbwhoeopãâãâãâ rei extended con...\n",
       "4      dear good friend happy inform successin gettin...\n",
       "                             ...                        \n",
       "995    dear frienddo accept sincere apology mail meet...\n",
       "996    desk ofmrwang qinhang seng bank ltddes voeux r...\n",
       "997           speak pm said secure ops connect residence\n",
       "998    mary landrieu asked attend dinner foster care ...\n",
       "999    oscar printed gate shangrila conf speechalso p...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "Let's get the 10 top words in ham and spam messages (**EXPLORATORY DATA ANALYSIS**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "bag_of_words = train.copy()\n",
    "# Tokenize sentences\n",
    "bag_of_words['text'] = bag_of_words['text'].map(lambda x: word_tokenize(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for ham: [('u', 115), ('pm', 115), ('would', 106), ('state', 103), ('president', 94), ('call', 91), ('time', 84), ('percent', 77), ('secretary', 76), ('work', 73)]\n",
      "Top 10 words for spam: [('money', 926), ('account', 800), ('bank', 748), ('fund', 708), ('u', 553), ('business', 476), ('transaction', 426), ('country', 414), ('transfer', 399), ('million', 388)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Get the top 10 words for label 0\n",
    "words_label_0 = [word for sublist in bag_of_words.loc[bag_of_words['label'] == 0, 'text'] for word in sublist]\n",
    "top_words_label_0 = Counter(words_label_0).most_common(10)\n",
    "\n",
    "# Get the top 10 words for label 1\n",
    "words_label_1 = [word for sublist in bag_of_words.loc[bag_of_words['label'] == 1, 'text'] for word in sublist]\n",
    "top_words_label_1 = Counter(words_label_1).most_common(10)\n",
    "\n",
    "print(\"Top 10 words for ham:\", top_words_label_0)\n",
    "print(\"Top 10 words for spam:\", top_words_label_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>money_mark</th>\n",
       "      <th>suspicious_words</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dear sir strictly private business proposal mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noracheryl emailed dozen memo haiti weekend pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear sirfmadamc know proposal might surprise e...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  money_mark  \\\n",
       "0  dear sir strictly private business proposal mi...      1           1   \n",
       "1                                                         0           1   \n",
       "2  noracheryl emailed dozen memo haiti weekend pl...      0           1   \n",
       "3  dear sirfmadamc know proposal might surprise e...      1           1   \n",
       "4                                                fyi      0           1   \n",
       "\n",
       "   suspicious_words  text_len  \n",
       "0                 1      1504  \n",
       "1                 0         0  \n",
       "2                 0       110  \n",
       "3                 1      1380  \n",
       "4                 0         3  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We add to the original dataframe two additional indicators (money symbols and suspicious words).\n",
    "money_simbol_list = \"|\".join([\"euro\",\"dollar\",\"pound\",\"€\",\"$\"])\n",
    "suspicious_words = \"|\".join([\"free\",\"cheap\",\"sex\",\"money\",\"account\",\"bank\",\"fund\",\"transfer\",\"transaction\",\"win\",\"deposit\",\"password\"])\n",
    "\n",
    "train['money_mark'] = train['text'].str.contains(money_simbol_list)*1\n",
    "train['suspicious_words'] = train['text'].str.contains(suspicious_words)*1\n",
    "train['text_len'] = train['text'].apply(lambda x: len(x)) \n",
    "\n",
    "test['money_mark'] = test['text'].str.contains(money_simbol_list)*1\n",
    "test['suspicious_words'] = test['text'].str.contains(suspicious_words)*1\n",
    "test['text_len'] = test['text'].apply(lambda x: len(x)) \n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>money_mark</th>\n",
       "      <th>suspicious_words</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usiness fact deceased man foreigner authorized...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy adjust afternoon going suggest pm start ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lael brainard confirmed afternoonmiguel rodrig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>friday march amsbwhoeopãâãâãâ rei extended con...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dear good friend happy inform successin gettin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  money_mark  \\\n",
       "0  usiness fact deceased man foreigner authorized...           1   \n",
       "1  happy adjust afternoon going suggest pm start ...           1   \n",
       "2  lael brainard confirmed afternoonmiguel rodrig...           1   \n",
       "3  friday march amsbwhoeopãâãâãâ rei extended con...           1   \n",
       "4  dear good friend happy inform successin gettin...           1   \n",
       "\n",
       "   suspicious_words  text_len  \n",
       "0                 1       799  \n",
       "1                 0       102  \n",
       "2                 0       155  \n",
       "3                 0        51  \n",
       "4                 1       807  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would the Bag of Words with Count Vectorizer concept work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the Count Vectorizers\n",
    "vectorizer_train = CountVectorizer()\n",
    "vectorizer_test = CountVectorizer()\n",
    "\n",
    "# Fit and transform the corpus\n",
    "X = vectorizer_train.fit_transform(train['text'])\n",
    "y = vectorizer_test.fit_transform(test['text'])\n",
    "\n",
    "# Convert the results to DataFrames for easy manipulation\n",
    "vectorized_df_train = pd.DataFrame(X.toarray(), columns=vectorizer_train.get_feature_names_out())\n",
    "vectorized_df_test = pd.DataFrame(y.toarray(), columns=vectorizer_test.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aac</th>\n",
       "      <th>aaclocated</th>\n",
       "      <th>aae</th>\n",
       "      <th>aag</th>\n",
       "      <th>aaronovitchon</th>\n",
       "      <th>abacha</th>\n",
       "      <th>abachabefore</th>\n",
       "      <th>abachac</th>\n",
       "      <th>abachace</th>\n",
       "      <th>abachaco</th>\n",
       "      <th>...</th>\n",
       "      <th>ãââolic</th>\n",
       "      <th>ãââ½</th>\n",
       "      <th>ãââ½trangers</th>\n",
       "      <th>ãââ½ãââ½</th>\n",
       "      <th>ãââ½ãââ½b</th>\n",
       "      <th>ãââ½ãââ½c</th>\n",
       "      <th>ãââ½ãââ½d</th>\n",
       "      <th>ãââ½ãââ½for</th>\n",
       "      <th>ãââ½ãââ½to</th>\n",
       "      <th>ãââ½ãââ½v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 19168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aac  aaclocated  aae  aag  aaronovitchon  abacha  abachabefore  abachac  \\\n",
       "0      0           0    0    0              0       0             0        0   \n",
       "1      0           0    0    0              0       0             0        0   \n",
       "2      0           0    0    0              0       0             0        0   \n",
       "3      0           0    0    0              0       0             0        0   \n",
       "4      0           0    0    0              0       0             0        0   \n",
       "..   ...         ...  ...  ...            ...     ...           ...      ...   \n",
       "995    0           0    0    0              0       0             0        0   \n",
       "996    0           0    0    0              0       0             0        0   \n",
       "997    0           0    0    0              0       0             0        0   \n",
       "998    0           0    0    0              0       0             0        0   \n",
       "999    0           0    0    0              0       0             0        0   \n",
       "\n",
       "     abachace  abachaco  ...  ãââolic  ãââ½  ãââ½trangers  ãââ½ãââ½  \\\n",
       "0           0         0  ...        0     0             0         0   \n",
       "1           0         0  ...        0     0             0         0   \n",
       "2           0         0  ...        0     0             0         0   \n",
       "3           0         0  ...        0     0             0         0   \n",
       "4           0         0  ...        0     0             0         0   \n",
       "..        ...       ...  ...      ...   ...           ...       ...   \n",
       "995         0         0  ...        0     0             0         0   \n",
       "996         0         0  ...        0     0             0         0   \n",
       "997         0         0  ...        0     0             0         0   \n",
       "998         0         0  ...        0     0             0         0   \n",
       "999         0         0  ...        0     0             0         0   \n",
       "\n",
       "     ãââ½ãââ½b  ãââ½ãââ½c  ãââ½ãââ½d  ãââ½ãââ½for  ãââ½ãââ½to  ãââ½ãââ½v  \n",
       "0            0          0          0            0           0          0  \n",
       "1            0          0          0            0           0          0  \n",
       "2            0          0          0            0           0          0  \n",
       "3            0          0          0            0           0          0  \n",
       "4            0          0          0            0           0          0  \n",
       "..         ...        ...        ...          ...         ...        ...  \n",
       "995          0          0          0            0           0          0  \n",
       "996          0          0          0            0           0          0  \n",
       "997          0          0          0            0           0          0  \n",
       "998          0          0          0            0           0          0  \n",
       "999          0          0          0            0           0          0  \n",
       "\n",
       "[1000 rows x 19168 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aabaibqblbbadaag</th>\n",
       "      <th>aacfcaadf</th>\n",
       "      <th>aaeefaafbedccc</th>\n",
       "      <th>aafiasiddiqui</th>\n",
       "      <th>aakamichelciyahoofrto</th>\n",
       "      <th>aallensmithfyahooeca</th>\n",
       "      <th>aam</th>\n",
       "      <th>aba</th>\n",
       "      <th>abacha</th>\n",
       "      <th>...</th>\n",
       "      <th>ãâãâãâ½</th>\n",
       "      <th>ãâãâãâ½million</th>\n",
       "      <th>ãâãâãâ½millionthis</th>\n",
       "      <th>ãâãâãâ½min</th>\n",
       "      <th>ãâãâãâ½minute</th>\n",
       "      <th>ãâãâãâ½nãâãâãâ½ãâãâãâ½aãâãâãâ½sãâãâãâ½ãâãâãâ½ãâãâãâ½wãâãâãâ½ãâãâãâ½aãâãâãâ½aãâãâãâ½ãâãâãâ½ãâãâãâ½bãâãâãâ½ãâãâãâãâãâ½ãâãâãâ½iãâãâãâ½hãâãâãâ½dãâãâãâ½uãâãâãâ½tãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½aãâãâãâ½aãâãâãâ½ãâãâãâ½aãâãâãâ½wãâãâãâ½ãâãâãâ½ãâãânãâãâãâ½ãâãâãâ½ãâãâyãâãâãâ½ãâãâãâãâãâ½aãâãâãâ½ãâãâãâ½ãâãâãâãâãâãâãâãâãâ½ãâãâãâ½nãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½c</th>\n",
       "      <th>ãâãâãâ½tranger</th>\n",
       "      <th>ãâãâãâ½tre</th>\n",
       "      <th>ãâãâãâ½tãâãâãâ½</th>\n",
       "      <th>ãâãâãâ½ãâãâãâ½uãâãâãâ½tãâãâãâ½ãâãâãâ½</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 19593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aa  aabaibqblbbadaag  aacfcaadf  aaeefaafbedccc  aafiasiddiqui  \\\n",
       "0     0                 0          0               0              0   \n",
       "1     0                 0          0               0              0   \n",
       "2     0                 0          0               0              0   \n",
       "3     0                 0          0               0              0   \n",
       "4     0                 0          0               0              0   \n",
       "..   ..               ...        ...             ...            ...   \n",
       "995   0                 0          0               0              0   \n",
       "996   0                 0          0               0              0   \n",
       "997   0                 0          0               0              0   \n",
       "998   0                 0          0               0              0   \n",
       "999   0                 0          0               0              0   \n",
       "\n",
       "     aakamichelciyahoofrto  aallensmithfyahooeca  aam  aba  abacha  ...  \\\n",
       "0                        0                     0    0    0       0  ...   \n",
       "1                        0                     0    0    0       0  ...   \n",
       "2                        0                     0    0    0       0  ...   \n",
       "3                        0                     0    0    0       0  ...   \n",
       "4                        0                     0    0    0       0  ...   \n",
       "..                     ...                   ...  ...  ...     ...  ...   \n",
       "995                      0                     0    0    0       0  ...   \n",
       "996                      0                     0    0    0       0  ...   \n",
       "997                      0                     0    0    0       0  ...   \n",
       "998                      0                     0    0    0       0  ...   \n",
       "999                      0                     0    0    0       0  ...   \n",
       "\n",
       "     ãâãâãâ½  ãâãâãâ½million  ãâãâãâ½millionthis  ãâãâãâ½min  ãâãâãâ½minute  \\\n",
       "0          0               0                   0           0              0   \n",
       "1          0               0                   0           0              0   \n",
       "2          0               0                   0           0              0   \n",
       "3          0               0                   0           0              0   \n",
       "4          0               0                   0           0              0   \n",
       "..       ...             ...                 ...         ...            ...   \n",
       "995        0               0                   0           0              0   \n",
       "996        0               0                   0           0              0   \n",
       "997        0               0                   0           0              0   \n",
       "998        0               0                   0           0              0   \n",
       "999        0               0                   0           0              0   \n",
       "\n",
       "     ãâãâãâ½nãâãâãâ½ãâãâãâ½aãâãâãâ½sãâãâãâ½ãâãâãâ½ãâãâãâ½wãâãâãâ½ãâãâãâ½aãâãâãâ½aãâãâãâ½ãâãâãâ½ãâãâãâ½bãâãâãâ½ãâãâãâãâãâ½ãâãâãâ½iãâãâãâ½hãâãâãâ½dãâãâãâ½uãâãâãâ½tãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½aãâãâãâ½aãâãâãâ½ãâãâãâ½aãâãâãâ½wãâãâãâ½ãâãâãâ½ãâãânãâãâãâ½ãâãâãâ½ãâãâyãâãâãâ½ãâãâãâãâãâ½aãâãâãâ½ãâãâãâ½ãâãâãâãâãâãâãâãâãâ½ãâãâãâ½nãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½c  \\\n",
       "0                                                    0                                                                                                                                                                                                                                                                                                                       \n",
       "1                                                    0                                                                                                                                                                                                                                                                                                                       \n",
       "2                                                    0                                                                                                                                                                                                                                                                                                                       \n",
       "3                                                    0                                                                                                                                                                                                                                                                                                                       \n",
       "4                                                    0                                                                                                                                                                                                                                                                                                                       \n",
       "..                                                 ...                                                                                                                                                                                                                                                                                                                       \n",
       "995                                                  0                                                                                                                                                                                                                                                                                                                       \n",
       "996                                                  0                                                                                                                                                                                                                                                                                                                       \n",
       "997                                                  0                                                                                                                                                                                                                                                                                                                       \n",
       "998                                                  0                                                                                                                                                                                                                                                                                                                       \n",
       "999                                                  0                                                                                                                                                                                                                                                                                                                       \n",
       "\n",
       "     ãâãâãâ½tranger  ãâãâãâ½tre  ãâãâãâ½tãâãâãâ½  \\\n",
       "0                 0           0                0   \n",
       "1                 0           0                0   \n",
       "2                 0           0                0   \n",
       "3                 0           0                0   \n",
       "4                 0           0                0   \n",
       "..              ...         ...              ...   \n",
       "995               0           0                0   \n",
       "996               0           0                0   \n",
       "997               0           0                0   \n",
       "998               0           0                0   \n",
       "999               0           0                0   \n",
       "\n",
       "     ãâãâãâ½ãâãâãâ½uãâãâãâ½tãâãâãâ½ãâãâãâ½  \n",
       "0                                        0  \n",
       "1                                        0  \n",
       "2                                        0  \n",
       "3                                        0  \n",
       "4                                        0  \n",
       "..                                     ...  \n",
       "995                                      0  \n",
       "996                                      0  \n",
       "997                                      0  \n",
       "998                                      0  \n",
       "999                                      0  \n",
       "\n",
       "[1000 rows x 19593 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "- Load the vectorizer\n",
    "\n",
    "- Vectorize all dataset\n",
    "\n",
    "- print the shape of the vetorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix for series1: (1000, 19168)\n",
      "Shape of TF-IDF matrix for series2: (1000, 19593)\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF vectorizer instances\n",
    "vect_train = TfidfVectorizer()\n",
    "vect_test = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform each series separately\n",
    "tfidf_train = vect_train.fit_transform(train['text'])\n",
    "tfidf_test = vect_test.fit_transform(test['text'])\n",
    "\n",
    "# Print the shape of the resulting vectorized datasets\n",
    "print(\"Shape of TF-IDF matrix for series1:\", tfidf_train.shape)\n",
    "print(\"Shape of TF-IDF matrix for series2:\", tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF DataFrame for series1:\n",
      "     aac  aaclocated  aae  aag  aaronovitchon  abacha  abachabefore  abachac  \\\n",
      "0    0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "1    0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "2    0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "3    0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "4    0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "..   ...         ...  ...  ...            ...     ...           ...      ...   \n",
      "995  0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "996  0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "997  0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "998  0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "999  0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "\n",
      "     abachace  abachaco  ...  ãââolic  ãââ½  ãââ½trangers  ãââ½ãââ½  \\\n",
      "0         0.0       0.0  ...      0.0   0.0           0.0       0.0   \n",
      "1         0.0       0.0  ...      0.0   0.0           0.0       0.0   \n",
      "2         0.0       0.0  ...      0.0   0.0           0.0       0.0   \n",
      "3         0.0       0.0  ...      0.0   0.0           0.0       0.0   \n",
      "4         0.0       0.0  ...      0.0   0.0           0.0       0.0   \n",
      "..        ...       ...  ...      ...   ...           ...       ...   \n",
      "995       0.0       0.0  ...      0.0   0.0           0.0       0.0   \n",
      "996       0.0       0.0  ...      0.0   0.0           0.0       0.0   \n",
      "997       0.0       0.0  ...      0.0   0.0           0.0       0.0   \n",
      "998       0.0       0.0  ...      0.0   0.0           0.0       0.0   \n",
      "999       0.0       0.0  ...      0.0   0.0           0.0       0.0   \n",
      "\n",
      "     ãââ½ãââ½b  ãââ½ãââ½c  ãââ½ãââ½d  ãââ½ãââ½for  ãââ½ãââ½to  ãââ½ãââ½v  \n",
      "0          0.0        0.0        0.0          0.0         0.0        0.0  \n",
      "1          0.0        0.0        0.0          0.0         0.0        0.0  \n",
      "2          0.0        0.0        0.0          0.0         0.0        0.0  \n",
      "3          0.0        0.0        0.0          0.0         0.0        0.0  \n",
      "4          0.0        0.0        0.0          0.0         0.0        0.0  \n",
      "..         ...        ...        ...          ...         ...        ...  \n",
      "995        0.0        0.0        0.0          0.0         0.0        0.0  \n",
      "996        0.0        0.0        0.0          0.0         0.0        0.0  \n",
      "997        0.0        0.0        0.0          0.0         0.0        0.0  \n",
      "998        0.0        0.0        0.0          0.0         0.0        0.0  \n",
      "999        0.0        0.0        0.0          0.0         0.0        0.0  \n",
      "\n",
      "[1000 rows x 19168 columns]\n",
      "\n",
      "TF-IDF DataFrame for series2:\n",
      "      aa  aabaibqblbbadaag  aacfcaadf  aaeefaafbedccc  aafiasiddiqui  \\\n",
      "0    0.0               0.0        0.0             0.0            0.0   \n",
      "1    0.0               0.0        0.0             0.0            0.0   \n",
      "2    0.0               0.0        0.0             0.0            0.0   \n",
      "3    0.0               0.0        0.0             0.0            0.0   \n",
      "4    0.0               0.0        0.0             0.0            0.0   \n",
      "..   ...               ...        ...             ...            ...   \n",
      "995  0.0               0.0        0.0             0.0            0.0   \n",
      "996  0.0               0.0        0.0             0.0            0.0   \n",
      "997  0.0               0.0        0.0             0.0            0.0   \n",
      "998  0.0               0.0        0.0             0.0            0.0   \n",
      "999  0.0               0.0        0.0             0.0            0.0   \n",
      "\n",
      "     aakamichelciyahoofrto  aallensmithfyahooeca  aam  aba  abacha  ...  \\\n",
      "0                      0.0                   0.0  0.0  0.0     0.0  ...   \n",
      "1                      0.0                   0.0  0.0  0.0     0.0  ...   \n",
      "2                      0.0                   0.0  0.0  0.0     0.0  ...   \n",
      "3                      0.0                   0.0  0.0  0.0     0.0  ...   \n",
      "4                      0.0                   0.0  0.0  0.0     0.0  ...   \n",
      "..                     ...                   ...  ...  ...     ...  ...   \n",
      "995                    0.0                   0.0  0.0  0.0     0.0  ...   \n",
      "996                    0.0                   0.0  0.0  0.0     0.0  ...   \n",
      "997                    0.0                   0.0  0.0  0.0     0.0  ...   \n",
      "998                    0.0                   0.0  0.0  0.0     0.0  ...   \n",
      "999                    0.0                   0.0  0.0  0.0     0.0  ...   \n",
      "\n",
      "     ãâãâãâ½  ãâãâãâ½million  ãâãâãâ½millionthis  ãâãâãâ½min  ãâãâãâ½minute  \\\n",
      "0        0.0             0.0                 0.0         0.0            0.0   \n",
      "1        0.0             0.0                 0.0         0.0            0.0   \n",
      "2        0.0             0.0                 0.0         0.0            0.0   \n",
      "3        0.0             0.0                 0.0         0.0            0.0   \n",
      "4        0.0             0.0                 0.0         0.0            0.0   \n",
      "..       ...             ...                 ...         ...            ...   \n",
      "995      0.0             0.0                 0.0         0.0            0.0   \n",
      "996      0.0             0.0                 0.0         0.0            0.0   \n",
      "997      0.0             0.0                 0.0         0.0            0.0   \n",
      "998      0.0             0.0                 0.0         0.0            0.0   \n",
      "999      0.0             0.0                 0.0         0.0            0.0   \n",
      "\n",
      "     ãâãâãâ½nãâãâãâ½ãâãâãâ½aãâãâãâ½sãâãâãâ½ãâãâãâ½ãâãâãâ½wãâãâãâ½ãâãâãâ½aãâãâãâ½aãâãâãâ½ãâãâãâ½ãâãâãâ½bãâãâãâ½ãâãâãâãâãâ½ãâãâãâ½iãâãâãâ½hãâãâãâ½dãâãâãâ½uãâãâãâ½tãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½aãâãâãâ½aãâãâãâ½ãâãâãâ½aãâãâãâ½wãâãâãâ½ãâãâãâ½ãâãânãâãâãâ½ãâãâãâ½ãâãâyãâãâãâ½ãâãâãâãâãâ½aãâãâãâ½ãâãâãâ½ãâãâãâãâãâãâãâãâãâ½ãâãâãâ½nãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½ãâãâãâ½c  \\\n",
      "0                                                  0.0                                                                                                                                                                                                                                                                                                                       \n",
      "1                                                  0.0                                                                                                                                                                                                                                                                                                                       \n",
      "2                                                  0.0                                                                                                                                                                                                                                                                                                                       \n",
      "3                                                  0.0                                                                                                                                                                                                                                                                                                                       \n",
      "4                                                  0.0                                                                                                                                                                                                                                                                                                                       \n",
      "..                                                 ...                                                                                                                                                                                                                                                                                                                       \n",
      "995                                                0.0                                                                                                                                                                                                                                                                                                                       \n",
      "996                                                0.0                                                                                                                                                                                                                                                                                                                       \n",
      "997                                                0.0                                                                                                                                                                                                                                                                                                                       \n",
      "998                                                0.0                                                                                                                                                                                                                                                                                                                       \n",
      "999                                                0.0                                                                                                                                                                                                                                                                                                                       \n",
      "\n",
      "     ãâãâãâ½tranger  ãâãâãâ½tre  ãâãâãâ½tãâãâãâ½  \\\n",
      "0               0.0         0.0              0.0   \n",
      "1               0.0         0.0              0.0   \n",
      "2               0.0         0.0              0.0   \n",
      "3               0.0         0.0              0.0   \n",
      "4               0.0         0.0              0.0   \n",
      "..              ...         ...              ...   \n",
      "995             0.0         0.0              0.0   \n",
      "996             0.0         0.0              0.0   \n",
      "997             0.0         0.0              0.0   \n",
      "998             0.0         0.0              0.0   \n",
      "999             0.0         0.0              0.0   \n",
      "\n",
      "     ãâãâãâ½ãâãâãâ½uãâãâãâ½tãâãâãâ½ãâãâãâ½  \n",
      "0                                      0.0  \n",
      "1                                      0.0  \n",
      "2                                      0.0  \n",
      "3                                      0.0  \n",
      "4                                      0.0  \n",
      "..                                     ...  \n",
      "995                                    0.0  \n",
      "996                                    0.0  \n",
      "997                                    0.0  \n",
      "998                                    0.0  \n",
      "999                                    0.0  \n",
      "\n",
      "[1000 rows x 19593 columns]\n"
     ]
    }
   ],
   "source": [
    "# Optionally, convert to DataFrames for inspection\n",
    "df_tfidf_train = pd.DataFrame(tfidf_train.toarray(), columns=vect_train.get_feature_names_out())\n",
    "df_tfidf_test = pd.DataFrame(tfidf_test.toarray(), columns=vect_test.get_feature_names_out())\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"\\nTF-IDF DataFrame for series1:\")\n",
    "print(df_tfidf_train)\n",
    "print(\"\\nTF-IDF DataFrame for series2:\")\n",
    "print(df_tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And the Train a Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.945\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       125\n",
      "           1       0.88      0.99      0.93        75\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.95      0.94       200\n",
      "weighted avg       0.95      0.94      0.95       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# X has been vectorised using TF-IDF in the cells above\n",
    "X = tfidf_train\n",
    "y = train['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Task - Implement a SPAM/HAM classifier\n",
    "\n",
    "https://www.kaggle.com/t/b384e34013d54d238490103bc3c360ce\n",
    "\n",
    "The classifier can not be changed!!! It must be the MultinimialNB with default parameters!\n",
    "\n",
    "Your task is to find the **best feature representation**.\n",
    "\n",
    "You can work with teams of two persons (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
